Before any storage solution is considered whether traditional hardware RAID or software RAID based, like Nexentastor with ZFS, it is critical to determine requirements and accept the fact there are always trade-offs between availability, storage capacity and performance. It is true that we can reconfigure storage after it has been deployed, but consider the challenges and costs of reconfiguring a production Storage Area Network especially when service outages may not be possible in your environment without significant planning, online data migration and coordination with customers. It is critical to understand your storage needs before any purchasing decisions are made to make sure that needs will be met when system is deployed. Nexentastor leverages software RAID with the next-generation ZFS file system. It is important to understand requirements, because without knowing requirements we will not know what trade-offs we should expect to make. There are always trade-offs in any technical decision that we make and having the right knowledge is essential to making choices during the design phase of your Nexentastor solution.  

There are several factors that ultimately all play a role in final configuration of the pool and we need address each factor and the decisions made after analyzing each factor. A storage solution may be used very differently by different organizations and one size never fits all. For example, we do not use a Ferrari to tow a boat out to the lake, likewise we do not think of trucks as high-performance roadsters. The same could be applied to storage. For example, when storing backups for periodic recovery our main concern is having enough capacity to retain backups to satisfy retention requirement imposed by the business, with secondary concern being redundancy to properly protect our retained backup data. At the same time, if we are running a latency critical stock-trading application, affect of even moderate latency from improperly configured storage may be completely unacceptable to such an application. These faactors play a huge role in our decisions about hardware, and pool configuration with ZFS.  

Complexity in Storage Area Networks is inherent and increases further whenever we begin to mix workloads. If we are using the same storage system for backups and for our highly latency-sensitive trading floor application, we have to make sure that we can maintain our latency requirement and have enough space to handle backup retention requirements all at the same time. Feasible, sure, but it requires careful planning, gathering of requirements and most critically understanding what a suitable storage solution for this environment is. Of course most modern SANs are used to provide storage back-ends for a multitude of applications with potentially very different requirements and knowing this we have to design a system, accepting certain trade-offs, capable of meeting these requirements as well as meeting growth projections, scaling with demands and handling natural spikes in demand, as well as failure of hardware, which inevitably occurs as disks, and any computer equipment fails.  

## General Understanding and Key Goals ##

Before we dig any further, there are a few key concepts about ZFS and storage in general that we have to understand and accept, as they will make it easier to further analyze our current storage need and the solution necessary to satisfy this need.

### Latency in the context of storage ###

We touch upon latency in this conversation and without digging deep into the subject matter, which on its own could easily have books written about it, let's briefly address latency. At the high level, when we talk within the context of storage, we should think of latency as the total amount of time it takes to complete IO, from the moment it has been issued by the application to the moment it has been satisfied. It is a key concept which we have to grasp, as it is critical in many high-performance environments today. User experience could very well suffer if key applications experience latency at the storage layer and does not have mechanisms to counter and obscure this latency. These mechanisms are typically some form of caching. Latency is observed through all the layers of a typical system. It takes time for an application to prepare and submit an IO. It takes time for that IO to be properly structured and sent to the filesystem, and for filesystem to process it perform actual IO to physical storage and return results. When we decouple storage from the system where the application resides, be it a single bare-metal system, or a virtual host with many VMs running on it, we also introduce latency at the network layer.

Latency is typically a result of the total time it takes for the IO request to be structured, perhaps delivered via the network, sent to disk, acknowledged, handled and result returned. Busy storage systems may be doing many thousands of IO operations per second, and in most cases, as is so typical of a SAN environment, IO from a number of applications is mixed together, resulting in a highly random pattern. Worst case scenario, which is quite common with homogeneous SANs is a 100% random workload which necessitates very frequent repositioning of the heads in a disk drive. Of course as is typical of most SANs, this is happening to many disks at the same time. Latency increases as disks become more busy. Data is typically queued in multiple places between the application (source of the IO) and the physical disks. Time spent in one of these queues will in fact add to the total latency number. 

Environments where virtualization is leveraged are even more susceptible to latency induced by storage, because there are more points at which IO contention can occur and where IO could be queued. Virtual machines running on a host will send their IOs to the host, and during peak times may in fact be saturating the host with IO requests, resulting in the host relying on its own often deep queues to hang on to IOs that it is unable to service right away. This gets infinitely more complicated when we begin to think about affect of peak times in systems that host virtual machines and the amount of IO that may be generated during these peak times.

When disks are taxed with non-sequential, (random) IO and they are struggling to keep-up, a natural result is an increase in latency. Flooding disks with IO, especially with modern SANs on multi-link 10GbE systems is not difficult. Understanding what latency is and what its impact is in our environment is essential to achieving solid and predictable performance from our storage solution.

Some applications deal with latency more gracefully than others and most environments will have a mix of applications, some of which handle it well, and some do not. We should always focus on the worst case scenarios, the outliers, because inevitably the worst case scenarios are those we are least prepared for. We will discuss this in more detail later. This subject could become infinitely complex and so we will try to address some of the basics of latency, but we have to remain cognizant of the fact that understanding latency and its impact to our environment is no trivial task.

### ZFS Approach to dealing with latency ###

Latency is inherent to spinning media because mechanical operations take more time to complete than it takes to move bits at nearly the speed of light. For this reason we attempt to employ flash-based storage devices as cache in front of main storage, which predominantly is spinning media. Flash devices do not, under normal circumstances, suffer from affects of latency, and in fact are specifically built to combat latency at every turn. What makes flash-based storage (Solid State Disks) particularly compelling is their ability to handle random IO extremely well, with incredibly low latency. Because highly random IO is so tough on spinning disks, pushing some of that work onto cache is one of ZFS' primary strengths. As always, realize that the more you pay the better the performance you will get. Because predominantly storage systems are asked to handle highly random IO, using flash based storage is an ideal way to combat latency. With ZFS in particular we can of course build solutions entirely out if SSDs, to deal with extreme low-latency requirements. But, more generally we can use SSDs as cache, allowing us to buffer both reads and writes, reducing the number of physical IO to disks, resulting in much lower latency while handling large very random workloads. More about this later.

Write throttling is another absolutely essential concept that is not native to many filesystems, but is a real factor when dealing with ZFS and Nexentastor in particular. Because latency is so critical, and we understand just how critical it is, we have ways to make sure that writes do not completely overwhelm storage and really impact read performance. Throttling writes is the approach we take to make sure that reads will complete in reasonable amount of time and not suffer significant latency costs. This can become rather problematic in environments where workloads shift drastically from being heavily write biased to read biased. Throttling of writes could in fact become so severe that a SAN may seem completely overrun, yet performance tools show almost no IO. This is a factor which we have to take into account and as we plan our environment we have to make sure that we do not constrain it from day one and design it for our specific workload footprint. Write throttle is a tool which was designed to manage short periods of abnormal amount of writes, unfortunately the side-affect is that prolonged write operations could be throttled so aggressively that eventually operations from the client begin to timeout and fail. Again, understanding our environment is key, and as we work to design our solution we need to think about whether we are going to be read or write-biased and design accordingly. While we are not diving deeply into this topic, this should at least give you the knowledge to ask questions that you did not know to ask prior to reading this. Ultimately our goal is get you to think in terms of storage and in particular ZFS, because with traditional (legacy) storage we did not have these factors to consider.

### Key Concepts of ZFS and Dynamic Striping ###

It is difficult to summarize ZFS in a few sentences, but the key concepts that we need to understand are as follows. ZFS first and foremost utilizes dynamic striping, which means that as we create more RAID groups inside our storage pool, or **volume** in Nexentastor terms, we increase throughput by making a wider stripe, which essentially means that we can do more work in parallel. It is easy to visualize each RAID group, also referred to as top-level VDEV as a single disk. So, a pool that consists of say 3 top-level VDEVs regardless of number of disks in each VDEV, can be thought of as having performance of 3 disks. The math is linear. As we add top-level VDEVs we linearly scale performance. To further illustrate this notion we can simply say that a pool with 3 top-level VDEVs will have 1/2 the throughput compared to a pool with 6 top-level VDEVs, and 1/4 the throughput of a 12 top-level VDEV pool. This is assuming that we are using the same disks in these conceptual configurations. In reality of course, performance varies based on a lot of factors, including the type of disk, it's rotational speed, average seek times, etc. This may sound complicated now, but will begin to make sense as you learn more about Nexentasor and ZFS in particular. The key take away here is that performance scales linearly with number of top-level VDEVs. So, when we think about our storage solution and when we think in terms of IOPs, and not Capacity we have to realize that if we are trying to match IOP performance of 3 disks working in parallel, we have to have at least 3 top-level VDEVs. One is tempted to argue that number of disks in each VDEV surely will make a difference, the key performance factor is parallelism of workload, which we can only achieve by striping data across more top-level VDEVs. With capacities today reaching 3TB with Enterprise-class drives we tend to think capacity and reduction of footprint, both of hardware and energy consumption. These are important matters, but the fact is, nothing replaces spindles, and with a SAN, more is better. If anything, we want more IOPs than we know what to do with, as that will reduce latency, reduce chance of write throttling, etc. For example, 20 mirrors with 7.2K 1TB drives are equal in capacity to 10 mirrors with 7.2K 2TB drives, but with 20 mirrors we have 2000 RAW IOPs vs. 1000 RAW IOPs with 10 mirrors of 2TB drives. We will continue talking about the importance of IOPs throughout the rest of this document.

### Aggressive Multi-level Read Caching ###

Another key feature of ZFS, one which makes it extremely performant in today's highly dynamic and diverse environments is the concept of a massive read cache. Historically, filesystems were not designed to allocate large caches for data to accelerate repeated retrieval of information, or to buffer writes, such as those generated by databases, which are particularly difficult on storage systems, due to the synchronous nature of the highly random transactions. With ZFS we try to maximize our ability to rapidly access data which has recently been accessed or is being frequently accessed by caching this data in one of two levels of cache. The first level of cache is system memory, abundance of which means we can allocate more physical blocks of memory to cache and retain more data and metadata to support larger working set sizes. Of course RAM is still a fairly limited commodity The second level of cache is flash-based storage, which when deployed on high-performance SSDs will allow for a far larger cache than could be obtained with first level of caching. This is very critical concept, and knowing your workload will help you make decisions about whether or not caching reads will be a significant strategy or only a marginal consideration.

### Write Caching by means of an Intent Log Mechanism ###

Because storage has historically struggled with handling applications that have a requirement of consistent on-disk data by writing information synchronously, built into ZFS is an Intent Log mechanism which essentially allows for synchronous writes to be grouped and ordered along with asynchronous writes and be sent to the disk in a more organized sequential stream, while rapidly responding to the application that is submitting synchronous write requests, allowing the application to continue working instead of waiting for storage to flush data to disk every time IO is sent to the storage system. At the same time ZFS groups IOs in order to sequentially flush them to disk, maximizing throughput and reducing on-disk fragmentation of data. This write cache is accomplished with high-performance NAND flash memory devices, such as SSDs and battery backed RAM devices. These devices do not suffer from latency inherent to spinning disks, and can very rapidly respond to highly random IO, which at an appropriate time is flushed to disks as part of a larger transaction group flush. All writes to disks could be thought of as a transaction and they either all succeed or fail. This fact and presence of the intent log assure data coherency and consistency. 

Again, this is something that we need to think about when we analyze our storage requirements. Many environments today require this level of caching, which is heavily used any time virtualization, OLTP applications and essentially any database engines are being deployed. If the environment has virtualized systems, databases and any applications that you know enforce data integrity by doing sync IO, addition of write cache is practically a requirement and will further benefit the storage solution by reducing amount of IO to the disks allowing the disks to handle other competing IO requests.

### Important goals of this document ###

We cannot forget that in all but a select few environments IO will be generated by multitude of sources and there is ongoing competition by applications to get data. Reads, writes, re-reads, and re-writes always compete for attention from storage and every application is only aware of its own needs and is completely oblivious to the concurrent demands of other applications in the environment. At any moment there may be several applications requesting that data is retrieved from or written to storage. Understanding the fact that we are working with highly dynamic systems that can at a moment's notice change from generating large sequential IO to small highly random IO is critical, and the more data we can aggregate about our particular environment the better equipped we will be in our ongoing research and design of the future storage solution.

The goal of this paper is to equip you with enough information to know what considerations to make and questions to ask during your research and analysis phase and is not intended to be a deep dive into ZFS. A more in-depth discussion about ZFS and its many unique features is strongly encouraged. We are barely scratching the surface of capabilities and intricacies of ZFS in this document.

In general there are a number of key elements that we need to address before we can start to think about our final design. This is a high-level list of these elements, and we will address each in detail.

* What problem are we trying to resolve with the planned storage solution?

* Striking a balance between Capacity and IOPs.

* Caching, performance improvement from caching and costly penalty of cold cache.

* What do the applications in our environment do.

* One pool or multiple, which is right and wrong.

* Do we want to accept running critical and noncritical applications on same storage realizing the real possibility that noncritical applications may result in performance degradation of the critical application.

* How critical are my applications and data and what is the minimum level of redundancy that will be acceptable to store this data? Level of redundancy has direct impact to capacity and performance.

* What is the aggregate ratio of reads to writes, and how much of the same data is read over and over or compared to how much data is read once and not read again for a long period of time, or ever?

* What sort of a growth factor are we dealing with, and is it in capacity IOPs or both.

### Problem Statement ###

Planning for a new storage solution is typically prefaced a need to resolve some existing problem. This problem may be current storage solution's inability to handle growing storage demands, decision to consolidate systems and storage into a more centralized configuration, deployment of some new systems that have storage requirements which you cannot meet with existing storage architecture, etc. Defining the problem is critical, because it will lead into other questions that have to be answered in order to properly scope and configure a new storage system.

It is common for the problem statement to be complex and multifaceted. There is not usually just one well defined problem, and most commonly a combination of issues, for example, consolidation of physical systems into a virtualized clusters, in order to reduce physical footprint and associated costs, while at the same time retiring an aging backup solution that is no longer able to meet your SLAs for completion of backups or perhaps lack of capacity to retain growing data produced by your applications and users.

To successfully define a problem statement we need to ultimately boil things down to the most basic of terms. Essentially, once we strip away most of the details we are looking at a question of Capacity, level of Data Protection and Performance and which two of these three are most important. Remember, we mentioned trade-offs at the beginning of the document, and with Nexentastor, just as with any other storage solution we have to choose between Capacity, Performance and Data Protection. Without understanding our problem we cannot begin to make any decisions about trade-offs that will need to be made. 

For example, if the problem which we are trying to resolve is mainly a lack of capacity to store fairly volatile data, value of which after 30 days diminishes considerably selecting double of triple parity, which of course means sacrificing capacity may not be the best option. If capacity is the main driver and only non-latency critical applications are going to rely on this solution, building a storage pool with only a few stripes may be completely acceptable. We may not even need to think about Read or Write caching, because latency is not issue, we do not have users interacting with the data or applications on this storage, and as long as we can achieve our capacity objective cost always being a factor, the benefit here may not be worth the added cost.

Similarly, if we are trying to achieve higher level of data availability and protection and are willing to sacrifice capacity, we may opt for a greater number of stripes. Having more stripes, or VDEVs actually increases our redundancy, because each VDEV is essentially a RAID group, and with a choice of single or double parity we can afford to lose one or two disks respectively, in each RAID group while still remaining operational. The compromise here is capacity, because as we increase number of VDEVs, we increase number of stripes and in turn amount of raw capacity required to store parity data. We always have to make some trade-off. The added benefit here is an improvement in performance as we parallelize workload. Finding a perfect balance is not easy, but critical.

A situation where we are supplying storage to a highly dynamic Web site that may consist of a multitude of virtualized systems running perhaps a trading floor application or multiple such applications with extreme sensitivity to latency and very high data-availability requirements is completely different from being mainly a data repository, and requires a completely different approach to the design. Here, we may not consider mirroring or single parity, seeking greater data protection provided by double or triple parity. In order to address our critical latency requirements we are likely going to increase number of RAID groups in order to better streamline IO and leverage both Read and Write caching, thereby reducing number of IO requests that have to hit our spinning disks, because inevitably mechanical disk devices, while they have great capacities all suffer from latency induced by positioning and re-positioning the heads. In some very specific use cases we may even consider an all-flash-based pool, again sacrificing capacity for higher price, but achieving outstanding low-latency numbers.

Please bear in mind that these are all extremely simplified examples to help us visualize the challenges with which we will be presented in our own environments. In reality, most of the time we will be dealing with a mixture of workloads some may not be concurrent, for example only occurring during certain times of day, while others being highly concurrent.

### Striking a balance between Capacity and IOPs ###

We cannot ignore a simple fact that when we talk about storage we are not only talking about how much we can store [capacity], but we are also talking about IOPs [number of operations performed per second]. Clearly, capacity is an absolute number that we can fairly easily understand and derive. For example, if we are building a SAN to consolidate 100 servers each of which on average uses 500GB of disk, we are looking at a 50TB solution, with perhaps another 20% overhead expectation, for a total of around 60TB. We are simplifying this conversation by not talking about compression, deduplication and other space conserving measures. These considerations should be made after we have a very good understanding of our data and our requirements and the depth of this discussion is largely out of scope of this higher-level document. The takeaway here is that it is fairly trivial to understand capacity requirements. Because we are used to the fact that when we build conventional servers with local storage on which our applications run, we typically do not think about IOPs, because dedicated storage in the servers typically has fast enough drives and enough of those drives to support most typical workloads.

However, as soon as we begin to talk about a SAN we have to immediately recognize that we are going to be looking at a very different disk configuration, and likely a far different IOP number than the aggregated number from all disks in the individual servers, for example the 100 servers that we trying to consolidate. For the sake of an argument assume that we have 6 ~100GB drives in each of the 100 servers for which we are consolidating storage. Let's also assume that each physical disk is an industry standard 10K SAS drive, capable of around 140 IOPs. Most servers are built with some level of RAID, so let's assume here that with a RAID controller these 6 drives per server are capable of ~500 IOPs. This is a conservative estimate, but this is purely to illustrate the subject matter, accurate numbers are not important. If we are to get a total IOPs capability of the 100 servers we come-up with **100 * 500 (IOPs) = 50,000 (IOPs)**. This is an impressive o we number, but what does it mean? This tells us that most, at any given moment, we may be doing as many as 50,000 IOPs if we are to look at the 100 servers running as one. The challenges with this picture are: a) do we know that any of the 100 servers ever actually hit the 500 IOPs number, and 2) if they do, do we know if there is ever a chance that all servers will hit anywhere near 500 IOPs at any given time? These may sound like straight-forward enough questions but they *absolutely* critical to our design of the SAN. Obviously, our worst case scenario here is that we may need 50,000 IOPs at some point from the SAN.

So how does this scenario translate to a ZFS-based storage solution like Nexentastor? Unfortunately, without a really in-depth analysis of this scenario several factors will remain vague, but at the high level the following are important to consider. Quickly recall our mention of dynamic striping and the concept of a *VDEV* which is a virtual representation of a group of physical disks in a stripe this is roughly the same as a RAID group in a traditional RAID array. To simplify things let's accept that as long as we are talking about the same, say 10K SAS disk, each VDEV is roughly equivalent in its IOPs capability to a single physical disk. For the moment, let's forget about Read and Write caching of ZFS. If we take the average of 140 IOPs per VDEV, we quickly realize that we will need as many  as 358 VDEVs to satisfy our hypothetical 50,000 IOPs requirement. If we take an typical *Raidz* configuration of 6 disks per VDEV, we are all-of-a-sudden looking at 2,148 disks. Again, takeaway here is IOPs are critical to consider, because our requirement of 60TB could easily be achieved with far, far fewer drives.

The more we know about how our applications work and the relationships between applications the easier it will be for us to design, from ground-up an appropriate and scalable solution. Every environment is different, and in reality your systems may only be utilizing a small percentage of their total IOPs potential, only hitting their maximum IOPs capability 5% of the time. Knowing this is essentially and cannot be understated. It is also not likely that all applications will hit their maximum IOPs potential at the same time, and in most environments it is typical to see a distribution of when different applications show maximum demand. Organizations with some fairly defined business hours will typically show highest IOPs during those hours. This may not be true in your organization and you need to know this.

### Caching and the penalty from cold cache ###

A number of times we referred to caching because it is a key differentiator between ZFS-based solutions and other traditional software RAID or hardware RAID solutions. Earlier we talked about an environment that could potentially have a maximum requirement of 50,000 IOPs, based on a back of the napkin calculations. With disks alone achieving this requirement may not be possible in our SAN solution. One answer to this is a robust caching mechanism to help with caching both reads and writes. As has been pointed out already ZFS aggressively caches recent data and frequently used data to one of the two levels of cache. Like other traditional filesystems RAM is used to cache both reads and writes. The difference is, with ZFS we treat ALL available RAM as cache and as RAM is higher speed and lower latency than SSDs or spinning disks, we try to consume almost the entire available RAM into what we call ARC (Adaptive Replacement Cache). Expensive RAID controllers with their limited caches simply cannot compete with a modern x86 system equipped with perhaps 96GB of RAM or more. ZFS caches *everything* in ARC, every bit of data that we read or write will pass through ARC. For every IO that we can service out of cache, we reduce the work on disks to improve performance of IO that will go to disk.

Asynchronous writes are at regular intervals flushed to disks. Write cache, also referred to as ZIL (ZFS Intent Log) or SLOG, when talking about dedicated devices is used to allow for caching of writes which normally would require immediate IO to disk to satisfy requirements of certain applications that force direct IO to ensure data consistency on disk. Forced flushes to disks from direct IO will necessarily bust caches, resulting in frequent flushes and will degrade ZFS' ability to coalesce IO and stream it to disks at regular intervals. The result of having dedicated ZIL devices is increased ability to turn synchronous IO into asynchronous IO, which translates to much better coalescing of all IO and better sequential streaming of writes to disks. One thing that disks do extremely well is sequential IO, ZFS is able to achieve this via this IO coalescing. Not all environments will benefit from dedicated ZIL devices (SLOG) equally. In most cases however having a dedicated ZIL results in a significant performance improvement. Few environments have workloads that will not benefit from a dedicated ZIL device, or multiple devices. Depending upon the size and scale of the SAN being configured multiple ZIL devices striped and mirrored may in fact be necessary. Scoping the specific requirements is not easy but working with our experienced professionals will help in determining the size of write cache that a particular environment will require.

It is critical to understand that operation of the ZIL is quite unique in that data is continuously written to the device, and almost never read. This is important to understand because majority of Solid State Disks today experience wear of cells in the memory modules from prolonged write cycles. To combat this manufacturers introduce wear leveling mechanisms, which while effective may not be effective enough when the SSD is used as a SLOG device. There are certain devices which are not affected by wear, due to their design, and we will recommend these devices as the first choice for the ZIL.

### Understanding Applications ###

Our storage system will need to correctly respond to needs of applications in our environment and for that to happen we have to understand what our applications do exactly and how they do it. First we have to accept that by their very nature SANs are extremely homogeneous, and it is extremely difficult to tell at a specific point in time how storage will behave, because of this homogeneity. In all but very few environments we deploy SANs to centralize, pool and unify storage, taking full advantage of being able to easily share data, reduce waste from having local disks on machines that see little use, reduce heat and power consumption from having local disks in each machine, increase data redundancy and protection. As we do this though we have to remain cognizant of the fact that some applications that used to run on local storage directly attached to a server now have to run on disks at the other end of a wire, competing with other applications that are just as hungry, if not more so for attention from disks. We sometimes wonder why an application that ran extremely well on just a few disks attached to a server is consistently under-performing after being moved to a SAN with many more disks and large caches. Ultimately we realize that we took for granted the fact that local disks were completely dedicated to this application, while on the SAN this application becomes one of the many applications in a big pond competing for time from disks.

It is not enough to understand how one or two applications work if we plan on 10 or more applications to leverage our storage solution. We absolutely have to understand them all. Even identical applications in different environments have unique footprints that may be wildly different from a typical footprint of this application in other environments, and so it is not meaningful to simply assume that based on some reference document we know what our applications are expected to do and what their IOPs requirements are. We need to carefully analyze each application first individually, isolating it against a blank background to get some understanding of just what the application does with regard to IO when there is absolutely no contention, i.e. local disks. For example, how much IO does our application require at any given moment? Are there times when IO requirements change rapidly, fluctuating due to perhaps other applications in the environment or certain actions that users may be taking, such as perhaps massive reporting during specific times of week or month. A contrived example is a batch processing application, perhaps there is a load stage lasting a number of hours every night, that requires far more IOPs than any other task in the application. We always have to look at the worst case scenarios and make our decisions based on the worst case scenarios. This is not always easy to achieve, but it is feasible to derive some mean for an application whether it be IO requirements, daily capacity requirements, etc., and reasonably well extrapolate worst case scenario based on experience.

As we research our applications we want to get some idea about whether the individual applications are biased towards reads or writes, as this will play a role in our final solution. Environments that tend to be more read-biased have a greater benefit from read cache than do write-biased environments, for obvious reasons. Few environments are extremely biased in one direction or the other, but understanding this will help us in making a decision about how much caching we want to buy on day one and how much we may be adding with time to further improve performance of the SAN. Write-heavy environments may be good candidates for multiple SLOG devices, perhaps two or more mirrors of high-performance SSDs, and perhaps instead of lower performing 7.2K drives 15K drives to further improve times for writes. Writes always require real IOPs to the disks, whereas reads may occur against cache and require no real IO from disks, or small amount of IO to satisfy the request.

Once we have a good idea about how individual applications behave we need to look at the bigger picture to gain some understanding of what the aggregated figures are. The goal is to get some insight into operating averages as well as the outliers, those times when IOPs are unusually high. Averages are always a risk to base our storage IOPs decisions on because of a risk that there are seasonal changes in the environment, or the outliers in our observations are far larger than the average figures, etc. The more IOPs data we collect the more accurate our averages are going to be. Collecting samples over a period of a number of weeks, perhaps a few times per hour will hopefully cover enough variability and result in a very solid average figure.

Another really critical consideration, one which requires understanding of the working set is whether caching will be effective in our environment. Caching is of course most effective in environments where same blocks of data are being requested over and over. In environments that process unique transactions and continuously handle new data caching is less effective, but the typical reason for having a SAN is consolidation which means workloads are aggregated and some may prove more cache-friendly than others. Again understanding our applications is essential. For example, if we have a large virtual environment and maintain and deploy new machines by cloning, or building from template, we may find that a small number of blocks are being accessed over and over, resulting in a small working set and extremely high cache hit ratio. At the other extreme we may be processing some large datasets with unique queries, and shipping results somewhere else away from the SAN. In this scenario we may find that caching helps little, simply because we continually read unique blocks.

In every environment there are a number of applications, some may be critical, others less so, some are really IO hungry and with low tolerance for latency, others far less so. While we cannot only focus on the critical applications we have to start with the most demanding applications and plan for a solution that will be adequate enough to make sure that under the worst case scenario these applications will have enough capacity and IOPs to continue running. The takeaway here is that we should never plan to deploy a SAN, no matter the design, with IOP capability lower than the baseline requirement of these key consumers.
